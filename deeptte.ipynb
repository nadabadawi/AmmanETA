{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script: Converting File Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pings to trajectories csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = 'careems data/pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'traj_fixed_time_2024-01-31.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "#convert to datetime\n",
    "df['location_read_at'] = pd.to_datetime(df['location_read_at'])\n",
    "\n",
    "#calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "#calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "trip_data = []\n",
    "\n",
    "#group by booking id\n",
    "# grouped = df.groupby('hash_booking_id')\n",
    "\n",
    "\n",
    "null_booking_id = '9b2d5b4678781e53038e91ea5324530a03f27dc1d0e5f6c9bc9d493a23be9de0'\n",
    "filtered_df = df[df['hash_booking_id'] != null_booking_id]  #filter out the null booking id\n",
    "grouped = filtered_df.groupby('hash_booking_id')\n",
    "\n",
    "\n",
    "for booking_id, group in grouped:\n",
    "    #sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "  \n",
    "    driver_id = group['hash_driver_id'].iloc[-1]\n",
    "    \n",
    "    #first instance of driver id to track switches\n",
    "    first_instance = group[group['hash_driver_id'] == driver_id].iloc[0]\n",
    "\n",
    "    time_id = first_instance['location_read_at']\n",
    "    \n",
    "    #filter out pings before switch\n",
    "    valid_group = group[group['location_read_at'] >= time_id]\n",
    "    \n",
    "    lngs = valid_group['longitude'].tolist()\n",
    "    lats = valid_group['latitude'].tolist()\n",
    "    \n",
    "   #dist gaps\n",
    "    dist_gaps = [0]\n",
    "    prev_lat = lats[0]\n",
    "    prev_lng = lngs[0]\n",
    "    cum_dist = 0\n",
    "    \n",
    "    #total distance\n",
    "    for lat, lng in zip(lats[1:], lngs[1:]):\n",
    "        dist = calculate_distance(prev_lat, prev_lng, lat, lng)\n",
    "        cum_dist += dist\n",
    "        dist_gaps.append(cum_dist)\n",
    "        prev_lat = lat\n",
    "        prev_lng = lng\n",
    "    \n",
    "    total_dist = cum_dist\n",
    "    \n",
    "    #time gaps\n",
    "    time_gaps = [(t - time_id).total_seconds() for t in valid_group['location_read_at']]\n",
    "    \n",
    "    #last time gap is total time\n",
    "    # total_time = time_gaps[-1] \n",
    "    total_time = calculate_time_difference(valid_group['location_read_at'].iloc[0], valid_group['location_read_at'].iloc[-1])\n",
    "\n",
    "    \n",
    "    trip_data.append([booking_id, driver_id, time_id, lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "\n",
    "output_df = pd.DataFrame(trip_data, columns=['booking_id', 'driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "#write output to csv\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to fixed_traj_new.json.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "#extract the date from filename\n",
    "def extract_date_from_filename(filename):\n",
    "    #regular expression to extract the date in the format YYYY-MM-DD\n",
    "    match = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", filename)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(0)  #return extracted date\n",
    "    else:\n",
    "        raise ValueError(\"Date not found in filename. Expected format: trajectories-YYYY-MM-DD.csv\")\n",
    "\n",
    "#get day of the week from date string\n",
    "def day_of_week(date_str):\n",
    "\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    #get day of the week (Monday is 0, Sunday is 6)\n",
    "    day_index = date.weekday()\n",
    "\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "    #get day of the week from the index\n",
    "    day_name = days[day_index]\n",
    "\n",
    "     #get day of the month (from 0 to 30)\n",
    "    day_of_month = date.day - 1  \n",
    "\n",
    "    return day_index, day_name, day_of_month\n",
    "\n",
    "#get time ID (minute of the day from 0 to 1439)\n",
    "def time_id_from_timestamp(timestamp_str):\n",
    "    # clean_timestamp_str = re.sub(r\"\\.\\d+\", \"\", timestamp_str)  #remove fractional seconds (not in new rectified pooling) \n",
    "    \n",
    "    time = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    total_minutes = time.hour * 60 + time.minute\n",
    "\n",
    "    return total_minutes\n",
    "\n",
    "\n",
    "\n",
    "def convert_csv_to_dicts(csv_file_path):\n",
    "    result = []\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            #convert to actual lists\n",
    "            row['time_gap'] = list(map(float, row['time_gap'].strip('[]').split(', ')))\n",
    "            row['lats'] = list(map(float, row['lats'].strip('[]').split(', ')))\n",
    "            row['lngs'] = list(map(float, row['lngs'].strip('[]').split(', ')))\n",
    "            row['dist_gap'] = list(map(float, row['dist_gap'].strip('[]').split(', ')))\n",
    "            \n",
    "            #date from filename\n",
    "            date_str = extract_date_from_filename(csv_file_path)\n",
    "\n",
    "            #day of week\n",
    "            week_id, name, date_id = day_of_week(date_str)\n",
    "            \n",
    "            #timeID is minute of day\n",
    "            time_id = time_id_from_timestamp(row['time_id'])\n",
    "            \n",
    "            #create dict with our desired keys\n",
    "            new_dict = {\n",
    "                'trip_id': row['booking_id'],\n",
    "                'time_gap': row['time_gap'],\n",
    "                'dist': float(row['dist']),\n",
    "                'lats': row['lats'],\n",
    "                'driverID': row['driver_id'],\n",
    "                'weekID': week_id,\n",
    "                'timeID': time_id,\n",
    "                'dateID': date_id,\n",
    "                'time': float(row['time']),\n",
    "                'lngs': row['lngs'],\n",
    "                'dist_gap': row['dist_gap']\n",
    "            }\n",
    "            json_str = json.dumps(new_dict, separators=(',', ':')) #convert to json string\n",
    "            result.append(json_str)\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_dicts_to_text(data, output_file_path):\n",
    "    if not data:\n",
    "        print(\"No data to write.\")\n",
    "        return\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for entry in data:\n",
    "            # print(entry)\n",
    "            #write json string to file\n",
    "            output_file.write(entry+'\\n')\n",
    "            output_file.flush()\n",
    "            \n",
    "\n",
    "csv_file_path = 'traj_fixed_time_2024-01-31.csv'\n",
    "output_file_path = 'fixed_traj_new.json' \n",
    "\n",
    "result = convert_csv_to_dicts(csv_file_path)\n",
    "\n",
    "write_dicts_to_text(result, output_file_path)\n",
    "\n",
    "\n",
    "print(f\"Data has been written to {output_file_path}.\")\n",
    "# print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping DriverID to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Read data from the existing JSON file\n",
    "json_file_path = 'new.json'\n",
    "\n",
    "json_file_path2 = 'new_mapped.json'\n",
    "# Read the content of the JSON file\n",
    "with open(json_file_path, 'r', encoding='utf-8') as input_file:\n",
    "    data = [json.loads(line) for line in input_file]  # Each line contains a JSON object\n",
    "\n",
    "# Step 2: Extract unique driver IDs\n",
    "driver_ids = set()  # Use a set to ensure uniqueness\n",
    "for entry in data:\n",
    "    driver_ids.add(entry['driverID'])\n",
    "\n",
    "# Step 3: Create a mapping from unique driver IDs to integers\n",
    "driver_id_map = {driver_id: idx for idx, driver_id in enumerate(driver_ids, start=1)}\n",
    "\n",
    "# Step 4: Apply the mapping to the data\n",
    "mapped_data = []\n",
    "for entry in data:\n",
    "    mapped_entry = entry.copy()  # Create a copy to avoid modifying the original\n",
    "    mapped_entry['driverID'] = driver_id_map[entry['driverID']]  # Replace driver ID with its integer mapping\n",
    "    mapped_data.append(mapped_entry)\n",
    "\n",
    "# Step 5: Write the modified data back to the JSON file\n",
    "with open(json_file_path2, 'w', encoding='utf-8') as output_file:\n",
    "    for entry in mapped_data:\n",
    "        json_str = json.dumps(entry, separators=(',', ':'))  # Convert to single-line JSON\n",
    "        output_file.write(json_str + '\\n')  # Write each entry to a new line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepTTE Calculations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "all_time_gaps = []\n",
    "all_lats = []\n",
    "all_lngs = []\n",
    "all_dist_gaps = []\n",
    "all_dists = []\n",
    "all_times = []\n",
    "\n",
    "for row in result:\n",
    "    all_time_gaps.extend(row['time_gap'])\n",
    "    all_lats.extend(row['lats'])\n",
    "    all_lngs.extend(row['lngs'])\n",
    "    all_dist_gaps.extend(row['dist_gap'])\n",
    "    all_dists.append(row['dist'])\n",
    "    all_times.append(row['time'])\n",
    "\n",
    "# Calculate the standard deviations and means for the collected data\n",
    "time_gap_std = statistics.stdev(all_time_gaps)\n",
    "time_gap_mean = statistics.mean(all_time_gaps)\n",
    "\n",
    "lats_std = statistics.stdev(all_lats)\n",
    "lats_mean = statistics.mean(all_lats)\n",
    "\n",
    "lngs_std = statistics.stdev(all_lngs)\n",
    "lngs_mean = statistics.mean(all_lngs)\n",
    "\n",
    "dist_gap_std = statistics.stdev(all_dist_gaps)\n",
    "dist_gap_mean = statistics.mean(all_dist_gaps)\n",
    "\n",
    "dist_std = statistics.stdev(all_dists)\n",
    "dist_mean = statistics.mean(all_dists)\n",
    "\n",
    "time_std = statistics.stdev(all_times)\n",
    "time_mean = statistics.mean(all_times)\n",
    "\n",
    "# Output the results    \n",
    "print(f\"Time gap standard deviation: {time_gap_std}\")\n",
    "print(f\"Time gap mean: {time_gap_mean}\")\n",
    "print(f\"Latitude standard deviation: {lats_std}\")\n",
    "print(f\"Latitude mean: {lats_mean}\")\n",
    "print(f\"Longitude standard deviation: {lngs_std}\")\n",
    "print(f\"Longitude mean: {lngs_mean}\")\n",
    "print(f\"Distance gap standard deviation: {dist_gap_std}\")\n",
    "print(f\"Distance gap mean: {dist_gap_mean}\")\n",
    "print(f\"Distance standard deviation: {dist_std}\")\n",
    "print(f\"Distance mean: {dist_mean}\")\n",
    "print(f\"Time standard deviation: {time_std}\")\n",
    "print(f\"Time mean: {time_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Str to Hexa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399\n"
     ]
    }
   ],
   "source": [
    "# # hex_driver_id = row['driver_id'].encode().hex()\n",
    "# id = \"0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399\"\n",
    "# print(id.encode.hex())\n",
    "\n",
    "# id = \"0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399\"\n",
    "# hex_value = id.encode(\"utf-8\").hex()  # Encoding and converting to hex\n",
    "# print(hex_value)\n",
    "\n",
    "# Hexadecimal string\n",
    "hex_str = \"0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399\"\n",
    "\n",
    "# Convert string to bytes (interpreting as hexadecimal)\n",
    "hex_bytes = bytes.fromhex(hex_str)\n",
    "\n",
    "# Convert bytes back to hexadecimal string (just for demonstration, you can use this `hex_bytes` as is)\n",
    "hex_str_from_bytes = hex_bytes.hex()\n",
    "\n",
    "print(hex_str_from_bytes)  # Should output the same as `hex_str`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this modified script:\n",
    "\n",
    "1. We import cudf and cupy instead of pandas and numpy, respectively.\n",
    "2. We use cudf.read_csv to read the CSV file into a cuDF DataFrame.\n",
    "3. We perform computations on GPU where applicable, such as distance calculations, using cupy arrays.\n",
    "4. We convert cuDF Series to cupy arrays using to_array() method when necessary.\n",
    "5. We utilize GPU-accelerated operations provided by cuDF and cupy for efficient data processing.\n",
    "\n",
    "> Please make sure to review the cuDF documentation for additional details and functionalities: https://docs.rapids.ai/api/cudf/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'Anon_Pings/anon_pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'trajectories-01-31.csv'\n",
    "\n",
    "# Read CSV file into a cuDF DataFrame\n",
    "df = cudf.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = cudf.to_datetime(df['location_read_at'] / 1000, unit='s')\n",
    "\n",
    "# Function to calculate distance between two points on GPU\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1 = cp.radians(lat1)\n",
    "    lon1 = cp.radians(lon1)\n",
    "    lat2 = cp.radians(lat2)\n",
    "    lon2 = cp.radians(lon2)\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Initialize list to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0]\n",
    "    lngs = group['longitude'].to_array()\n",
    "    lats = group['latitude'].to_array()\n",
    "    \n",
    "    # Initialize dist_gaps to store cumulative distances on GPU\n",
    "    dist_gaps = cp.zeros_like(lats)\n",
    "    prev_lat = lats[0]\n",
    "    prev_lng = lngs[0]\n",
    "    cum_dist = 0\n",
    "    \n",
    "    # Calculate total distance\n",
    "    for i in range(1, len(lats)):\n",
    "        lat = lats[i]\n",
    "        lng = lngs[i]\n",
    "        dist = calculate_distance(prev_lat, prev_lng, lat, lng)\n",
    "        cum_dist += dist\n",
    "        dist_gaps[i] = cum_dist\n",
    "        prev_lat = lat\n",
    "        prev_lng = lng\n",
    "    \n",
    "    total_dist = cum_dist\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time gaps\n",
    "    time_gaps = (group['location_read_at'] - time_id).dt.total_seconds().to_array()\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([booking_id, driver_id, time_id] + [lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create cuDF DataFrame from trip data\n",
    "output_df = cudf.DataFrame(trip_data, columns=['booking_id', 'driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output cuDF DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distance travelled from another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance travelled for booking_id 29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913: 11.79921054840088 km\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def filter_csv_by_booking_id(csv_file, booking_id):\n",
    "    with open(csv_file, 'r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Initialize distance variable\n",
    "        distance_travelled_km = None\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Check if the booking_id matches the desired booking_id\n",
    "            if row['booking_id'] == booking_id:\n",
    "                # Extract the distance_travelled_km for the matching row\n",
    "                distance_travelled_km = row['distance_travelled_km']\n",
    "                break\n",
    "        \n",
    "        # Check if distance_travelled_km was found\n",
    "        if distance_travelled_km is not None:\n",
    "            print(f\"Distance travelled for booking_id {booking_id}: {distance_travelled_km} km\")\n",
    "        else:\n",
    "            print(f\"No distance travelled found for booking_id {booking_id}\")\n",
    "\n",
    "# Example usage:\n",
    "input_csv_file = 'Pooling/anon_pooling_jan_24_amman.csv'\n",
    "desired_booking_id = '29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913'  # Replace 'ABC123' with the desired booking_id\n",
    "filter_csv_by_booking_id(input_csv_file, desired_booking_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Test CSV file with n trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "\n",
    "def filter_entries(input_file, output_file, booking_ids):\n",
    "    # Check if the output file exists, if not, create it with headers\n",
    "    file_exists = os.path.isfile(output_file)\n",
    "    with open(output_file, 'a', newline='') as csvfile:\n",
    "        fieldnames = []  # Initialize empty list for fieldnames\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            with open(input_file, 'r', newline='') as input_csv:\n",
    "                reader = csv.DictReader(input_csv)\n",
    "                fieldnames = reader.fieldnames  # Get fieldnames from input file\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "        with open(input_file, 'r', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                if row['booking_id'] in booking_ids:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'Anon_Pings/anon_pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'test.csv'\n",
    "booking_ids = ['88165aea83997095058b3f6676c1e3bdeedb4802c52afc9c412b1c610713a1ca',\n",
    "               '3846a90814f7e29b6b0c11717b40afd9fcd86ac7aae41fa9ffe19fbfcc4bfe26',\n",
    "               '29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913']\n",
    "\n",
    "filter_entries(input_file, output_file, booking_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distance functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29400740273246023\n",
      "0.325896974688779\n",
      "0.6199043774212392\n",
      "0.47439900315363936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "lats = [30.64392,30.642129,30.64393,30.640667,30.637807,30.634062,30.630342,30.62768,30.624637,30.622056,30.620839,30.62065,30.620698,30.620622,30.620588,30.621499,30.625048,30.625105,30.625109,30.624056,30.623248,30.626844]\n",
    "lngs = [104.115353,104.113091,104.110404,104.108335,104.106304,104.104013,104.101653,104.100465,104.097907,104.095813,104.091939,104.087057,104.083797,104.080276,104.076107,104.071857,104.072423,104.072982,104.073218,104.076707,104.076795,104.076552]\n",
    "\n",
    "dist_gaps = [0] + [calculate_distance(lats[i], lngs[i], lats[i + 1], lngs[i + 1]) for i in range(len(lats)-1)]\n",
    "\n",
    "# print(dist_gaps)\n",
    "\n",
    "result1 = calculate_distance(30.64392, 104.115353, 30.642129, 104.113091)\n",
    "result2 = calculate_distance(30.642129, 104.113091, 30.64393, 104.110404)\n",
    "result3 = calculate_distance(30.64392, 104.115353, 30.64393, 104.110404)\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result1+result2)\n",
    "print(result3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
