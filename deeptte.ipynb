{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting File Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'test.csv'\n",
    "output_file = 'deeptte.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = pd.to_datetime(df['location_read_at'])\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Initialize lists to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0]\n",
    "    lngs = group['longitude'].tolist()\n",
    "    lats = group['latitude'].tolist()\n",
    "    \n",
    "    # Calculate total distance\n",
    "    total_dist = sum(calculate_distance(lats[i], lngs[i], lats[i+1], lngs[i+1]) for i in range(len(lats)-1))\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time and distance gaps\n",
    "    time_gaps = [(t - time_id).total_seconds() for t in group['location_read_at']]\n",
    "    dist_gaps = [0] + [geodesic((lats[i], lngs[i]), (lats[i+1], lngs[i+1])).kilometers for i in range(len(lats)-1)]\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([driver_id, time_id, lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create DataFrame from trip data\n",
    "output_df = pd.DataFrame(trip_data, columns=['driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'test.csv'\n",
    "output_file = 'deeptte.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = pd.to_datetime(df['location_read_at'] / 1000, unit='s')\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Initialize lists to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0].strftime('%Y-%m-%d %H:%M:%S')  # Convert to normal time\n",
    "    lngs = group['longitude'].tolist()\n",
    "    lats = group['latitude'].tolist()\n",
    "    \n",
    "    # Calculate total distance\n",
    "    total_dist = sum(calculate_distance(lats[i], lngs[i], lats[i+1], lngs[i+1]) for i in range(len(lats)-1))\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time and distance gaps\n",
    "    time_gaps = [(t - group['location_read_at'].iloc[0]).total_seconds() for t in group['location_read_at']]\n",
    "    dist_gaps = [0] + [geodesic((lats[i], lngs[i]), (lats[i+1], lngs[i+1])).kilometers for i in range(len(lats)-1)]\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([driver_id, time_id, lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create DataFrame from trip data\n",
    "output_df = pd.DataFrame(trip_data, columns=['driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'test.csv'\n",
    "output_file = 'deeptte3.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = pd.to_datetime(df['location_read_at'] / 1000, unit='s')\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).meters\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Initialize list to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0]\n",
    "    lngs = group['longitude'].tolist()\n",
    "    lats = group['latitude'].tolist()\n",
    "    \n",
    "    # Calculate total distance\n",
    "    # total_dist = sum(calculate_distance(lats[i], lngs[i], lats[i+1], lngs[i+1]) for i in range(len(lats)-1))\n",
    "    total_dist = sum(calculate_distance(lats[i], lngs[i], lats[i+1], lngs[i+1]) for i in range(len(lats)-1))\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time and distance gaps\n",
    "    time_gaps = [(t - time_id).total_seconds() for t in group['location_read_at']]\n",
    "    # dist_gaps = [0] + [geodesic((lats[i], lngs[i]), (lats[i+1], lngs[i+1])).kilometers for i in range(len(lats)-1)]\n",
    "    dist_gaps = [calculate_distance(lats[0], lngs[0], lats[i], lngs[i]) for i in range(len(lats)-1)]\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([booking_id, driver_id, time_id, lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create DataFrame from trip data\n",
    "output_df = pd.DataFrame(trip_data, columns=['booking_id', 'driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'Anon_Pings/anon_pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'trajectories-01-31.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = pd.to_datetime(df['location_read_at'] / 1000, unit='s')\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Initialize list to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0]\n",
    "    lngs = group['longitude'].tolist()\n",
    "    lats = group['latitude'].tolist()\n",
    "    \n",
    "    # Initialize dist_gaps to store cumulative distances\n",
    "    dist_gaps = [0]\n",
    "    prev_lat = lats[0]\n",
    "    prev_lng = lngs[0]\n",
    "    cum_dist = 0\n",
    "    \n",
    "    # Calculate total distance\n",
    "    for lat, lng in zip(lats[1:], lngs[1:]):\n",
    "        dist = calculate_distance(prev_lat, prev_lng, lat, lng)\n",
    "        cum_dist += dist\n",
    "        dist_gaps.append(cum_dist)\n",
    "        prev_lat = lat\n",
    "        prev_lng = lng\n",
    "    \n",
    "    total_dist = cum_dist\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time gaps\n",
    "    time_gaps = [(t - time_id).total_seconds() for t in group['location_read_at']]\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([booking_id, driver_id, time_id, lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create DataFrame from trip data\n",
    "output_df = pd.DataFrame(trip_data, columns=['booking_id', 'driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CSV to Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajectories-01-31.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Convert the CSV data to the desired format\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_csv_to_dicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Print the first entry to verify the format\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m, in \u001b[0;36mconvert_csv_to_dicts\u001b[1;34m(csv_file_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m     date_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Add trip_id (same as booking_id)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m trip_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooking_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming booking_id is an integer\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Create a new dictionary with desired keys\u001b[39;00m\n\u001b[0;32m     43\u001b[0m new_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_id\u001b[39m\u001b[38;5;124m'\u001b[39m: trip_id,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_gap\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_gap\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_gap\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_gap\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     56\u001b[0m }\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '0012cf835ee80e59fefbe618282b2edc082940ddba6a4658e2626801026e2399'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def convert_csv_to_dicts(csv_file_path):\n",
    "    result = []\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            # Convert string representation of lists to actual lists\n",
    "            row['time_gap'] = list(map(float, row['time_gap'].strip('[]').split(', ')))\n",
    "            row['lats'] = list(map(float, row['lats'].strip('[]').split(', ')))\n",
    "            row['lngs'] = list(map(float, row['lngs'].strip('[]').split(', ')))\n",
    "            row['dist_gap'] = list(map(float, row['dist_gap'].strip('[]').split(', ')))\n",
    "            # Check if the 'driver_id' field has the expected format\n",
    "            # if '_' in row['driver_id']:\n",
    "            #     driver_id_parts = row['driver_id'].split('_')\n",
    "            #     if len(driver_id_parts) == 2 and driver_id_parts[1].isdigit():\n",
    "            #         driver_id = int(driver_id_parts[1])\n",
    "            #     else:\n",
    "            #         driver_id = None\n",
    "            # else:\n",
    "            #     driver_id = None\n",
    "            week_id = 2\n",
    "            # date_id = \n",
    "            # Check if the 'time_id' field has the expected format\n",
    "            if '-W' in row['time_id']:\n",
    "                time_id_parts = row['time_id'].split('-W')\n",
    "                if len(time_id_parts) == 2 and time_id_parts[1].isdigit():\n",
    "                    week_id = int(time_id_parts[1].split('-')[0])\n",
    "                    time_id = int(time_id_parts[1].split('-')[1])\n",
    "                    date_id = int(time_id_parts[0])\n",
    "                else:\n",
    "                    week_id = None\n",
    "                    time_id = None\n",
    "                    date_id = None\n",
    "            else:\n",
    "                week_id = None\n",
    "                time_id = None\n",
    "                date_id = None\n",
    "            \n",
    "            # Add trip_id (same as booking_id)\n",
    "            trip_id = int(row['booking_id'])  # Assuming booking_id is an integer\n",
    "            \n",
    "            # Create a new dictionary with desired keys\n",
    "            new_dict = {\n",
    "                'trip_id': trip_id,\n",
    "                'time_gap': row['time_gap'],\n",
    "                'dist': float(row['dist']),\n",
    "                'lats': row['lats'],\n",
    "                'driverID': driver_id,\n",
    "                'weekID': week_id,\n",
    "                # 'states': row['states'],  # Assuming 'states' field is already formatted correctly\n",
    "                'timeID': time_id,\n",
    "                'dateID': date_id,\n",
    "                'time': float(row['time']),\n",
    "                'lngs': row['lngs'],\n",
    "                'dist_gap': row['dist_gap']\n",
    "            }\n",
    "            result.append(new_dict)\n",
    "    return result\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "csv_file_path = 'trajectories-01-31.csv'\n",
    "\n",
    "# Convert the CSV data to the desired format\n",
    "result = convert_csv_to_dicts(csv_file_path)\n",
    "\n",
    "# Print the first entry to verify the format\n",
    "print(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_gap': [0.0, 9.972, 14.977999, 19.974999, 24.972, 29.967999, 34.963999, 39.987999, 44.979, 49.986, 54.983, 60.0, 64.985, 69.985, 74.974999, 79.986999, 84.979, 89.973, 94.99, 99.96, 107.973, 117.987999, 122.985, 127.983, 132.973999, 138.009999, 142.986, 147.993999, 152.979, 157.980999, 162.98, 167.989, 172.967999, 177.969, 182.972, 187.977999, 192.990999, 197.972, 202.976999, 207.979, 212.979, 222.977999, 227.973, 232.967, 237.997999, 242.98, 247.979, 252.973, 257.976999, 262.976, 267.969, 272.973999, 277.976999, 282.98, 287.977999, 292.973, 297.977999, 302.967, 307.967, 307.967, 316.962, 321.969, 326.970999, 331.969, 341.977999, 341.977999, 353.973, 363.963999, 373.973, 383.963999, 398.962, 408.947999, 418.963999, 428.967, 438.947, 448.964999, 458.967, 468.979, 478.960999, 488.963, 498.970999, 508.983999, 518.976999, 528.970999, 538.993, 558.98, 578.97, 593.977999, 603.977999, 613.985, 623.979, 633.973, 643.98, 653.977999, 663.98, 673.976999, 688.976, 698.983, 708.979, 718.996, 728.997999, 739.0, 758.990999, 763.973999, 768.983, 768.983, 777.986, 783.009, 787.996999, 793.042, 797.996999, 802.986999, 807.997999, 813.006, 818.010999, 827.993999, 832.996, 837.997999, 843.006999, 848.0, 853.023, 857.999, 863.012, 868.016999, 873.016, 893.048, 898.010999, 903.059999, 908.003999, 913.000999, 918.003999, 923.023999, 928.016, 937.996999, 943.016999, 948.006, 953.056999, 958.008, 963.003, 968.016, 973.000999, 978.010999, 983.049, 988.003999, 993.008, 998.0, 1002.996, 1008.000999, 1013.015, 1018.008, 1023.003, 1027.993999, 1033.010999, 1038.016999, 1048.042999, 1053.068, 1058.069, 1063.054, 1068.005, 1073.006999, 1078.009999, 1083.049, 1087.997999, 1093.009999, 1098.006999, 1103.016, 1113.055, 1118.015, 1123.013999, 1133.009, 1163.055999, 1168.003, 1172.993999, 1178.015, 1183.006, 1188.0, 1193.006999, 1198.003, 1208.003, 1212.997999, 1218.003, 1223.003999, 1228.006, 1232.996999, 1238.009, 1243.003, 1248.012, 1253.006, 1258.006, 1263.006999, 1268.008, 1273.005, 1278.013, 1283.008, 1288.003999, 1293.013, 1298.006, 1303.006, 1308.009, 1313.015, 1313.015, 1322.108, 1330.002, 1334.999, 1339.996, 1355.009999, 1360.000999, 1365.006999, 1370.012, 1375.0, 1380.032999, 1385.003, 1390.016999, 1395.010999, 1400.003, 1404.990999, 1409.996, 1415.012, 1419.993999, 1425.003999, 1435.010999, 1440.003, 1444.996999, 1450.006999, 1455.010999, 1470.002, 1474.993, 1480.019, 1494.990999, 1500.009999, 1504.989, 1512.332, 1521.163, 1526.164999, 1531.187999, 1536.2, 1541.240999, 1556.258, 1561.293999, 1566.306999, 1571.328999, 1576.394, 1581.758, 1586.398, 1591.41, 1596.423, 1601.467, 1611.479, 1616.720999], 'dist': 8.411881649504956, 'lats': [31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.955, 31.954, 31.954, 31.954, 31.954, 31.954, 31.954, 31.953, 31.953, 31.953, 31.953, 31.953, 31.953, 31.953, 31.953, 31.952, 31.951, 31.951, 31.951, 31.95, 31.95, 31.949, 31.949, 31.949, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.948, 31.947, 31.947, 31.946, 31.945, 31.945, 31.944, 31.943, 31.942, 31.942, 31.941, 31.94, 31.94, 31.939, 31.938, 31.938, 31.937, 31.936, 31.935, 31.935, 31.934, 31.933, 31.932, 31.932, 31.931, 31.93, 31.93, 31.929, 31.928, 31.926, 31.926, 31.925, 31.924, 31.923, 31.922, 31.921, 31.921, 31.92, 31.919, 31.918, 31.917, 31.916, 31.915, 31.914, 31.913, 31.909, 31.909, 31.909, 31.908, 31.908, 31.908, 31.907, 31.907, 31.906, 31.906, 31.906, 31.905, 31.905, 31.905, 31.905, 31.904, 31.904, 31.904, 31.903, 31.904, 31.904, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903, 31.903], 'driverID': None, 'weekID': None, 'timeID': None, 'dateID': None, 'time': 1616.720999, 'lngs': [35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.856, 35.856, 35.856, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.857, 35.858, 35.858, 35.857, 35.857, 35.856, 35.856, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.855, 35.856, 35.856, 35.857, 35.857, 35.858, 35.858, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.858, 35.857, 35.857, 35.856, 35.855, 35.855, 35.855, 35.854, 35.854, 35.854, 35.854, 35.854, 35.855, 35.855, 35.856, 35.857, 35.857, 35.858, 35.858, 35.859, 35.859, 35.86, 35.86, 35.86, 35.86, 35.86, 35.86, 35.86, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.859, 35.863, 35.864, 35.864, 35.865, 35.866, 35.866, 35.867, 35.867, 35.867, 35.868, 35.868, 35.868, 35.868, 35.868, 35.868, 35.868, 35.868, 35.868, 35.868, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.867, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.867, 35.867, 35.867, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866, 35.866], 'dist_gap': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1108860134817217, 0.1108860134817217, 0.1108860134817217, 0.1108860134817217, 0.1108860134817217, 0.1108860134817217, 0.22177200947734943, 0.22177200947734943, 0.22177200947734943, 0.31631332145340685, 0.31631332145340685, 0.31631332145340685, 0.4108546334287925, 0.4108546334287925, 0.5217406119391375, 0.6326265729635927, 0.6326265729635927, 0.6326265729635927, 0.7435125165040279, 0.7435125165040279, 0.8543984425580702, 0.8543984425580702, 0.8543984425580702, 1.0001194631235417, 1.0001194631235417, 1.0946658958368225, 1.0946658958368225, 1.1892123285501033, 1.1892123285501033, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.2837587612640557, 1.3783051939780082, 1.3783051939780082, 1.472851626691289, 1.472851626691289, 1.5673980594045698, 1.5673980594045698, 1.6619444921185222, 1.6619444921185222, 1.6619444921185222, 1.6619444921185222, 1.6619444921185222, 1.7728303832057386, 1.7728303832057386, 1.883716256807575, 1.994602112925899, 1.994602112925899, 2.105487951561873, 2.25121222764987, 2.396937154799542, 2.396937154799542, 2.542662732996116, 2.68838896222694, 2.68838896222694, 2.7992747134512754, 2.9450022447055804, 2.9450022447055804, 3.055887960966892, 3.166773659747376, 3.277659341048191, 3.372219084307628, 3.483104748126759, 3.6288355341953946, 3.7745669711832885, 3.7745669711832885, 3.920299059076729, 4.031184652979676, 4.125749514383445, 4.236635090805922, 4.382369131331259, 4.604140196787627, 4.604140196787627, 4.715025703299138, 4.825911192333164, 4.936796663890157, 5.047682117970927, 5.193420714141674, 5.193420714141674, 5.304306133270304, 5.4151915349233715, 5.526076919100975, 5.6369622858025155, 5.747847635030208, 5.858732966784512, 5.969618281063056, 6.080503577869121, 6.663485291092209, 6.758071640828118, 6.758071640828118, 6.903818695637224, 6.998406068309918, 6.998406068309918, 7.144153773683484, 7.144153773683484, 7.255038948180815, 7.349628366641246, 7.349628366641246, 7.460513523667268, 7.460513523667268, 7.460513523667268, 7.460513523667268, 7.57139866322173, 7.57139866322173, 7.57139866322173, 7.682283785306499, 7.828034092799734, 7.828034092799734, 7.9389192148845025, 7.9389192148845025, 7.9389192148845025, 7.9389192148845025, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.033511701808592, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.128104188732683, 8.222696675656774, 8.222696675656774, 8.222696675656774, 8.222696675656774, 8.222696675656774, 8.222696675656774, 8.222696675656774, 8.317289162580865, 8.317289162580865, 8.317289162580865, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956, 8.411881649504956]}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def convert_csv_to_dicts(csv_file_path):\n",
    "    result = []\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            # Convert string representation of lists to actual lists\n",
    "            row['time_gap'] = list(map(float, row['time_gap'].strip('[]').split(', ')))\n",
    "            row['lats'] = list(map(float, row['lats'].strip('[]').split(', ')))\n",
    "            row['lngs'] = list(map(float, row['lngs'].strip('[]').split(', ')))\n",
    "            row['dist_gap'] = list(map(float, row['dist_gap'].strip('[]').split(', ')))\n",
    "            # Check if the 'driver_id' field has the expected format\n",
    "            if '_' in row['driver_id']:\n",
    "                driver_id_parts = row['driver_id'].split('_')\n",
    "                if len(driver_id_parts) == 2 and driver_id_parts[1].isdigit():\n",
    "                    driver_id = int(driver_id_parts[1])\n",
    "                else:\n",
    "                    driver_id = None\n",
    "            else:\n",
    "                driver_id = None\n",
    "            \n",
    "            # Check if the 'time_id' field has the expected format\n",
    "            if '-W' in row['time_id']:\n",
    "                time_id_parts = row['time_id'].split('-W')\n",
    "                if len(time_id_parts) == 2 and time_id_parts[1].isdigit():\n",
    "                    week_id = int(time_id_parts[1].split('-')[0])\n",
    "                    time_id = int(time_id_parts[1].split('-')[1])\n",
    "                    date_id = int(time_id_parts[0])\n",
    "                else:\n",
    "                    week_id = None\n",
    "                    time_id = None\n",
    "                    date_id = None\n",
    "            else:\n",
    "                week_id = None\n",
    "                time_id = None\n",
    "                date_id = None\n",
    "            \n",
    "            # Create a new dictionary with desired keys\n",
    "            new_dict = {\n",
    "                'time_gap': row['time_gap'],\n",
    "                'dist': float(row['dist']),\n",
    "                'lats': row['lats'],\n",
    "                'driverID': driver_id,\n",
    "                'weekID': week_id,\n",
    "                # 'states': row['states'],  # Assuming 'states' field is already formatted correctly\n",
    "                'timeID': time_id,\n",
    "                'dateID': date_id,\n",
    "                'time': float(row['time']),\n",
    "                'lngs': row['lngs'],\n",
    "                'dist_gap': row['dist_gap']\n",
    "            }\n",
    "            result.append(new_dict)\n",
    "    return result\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "csv_file_path = 'trajectories-01-31.csv'\n",
    "\n",
    "# Convert the CSV data to the desired format\n",
    "result = convert_csv_to_dicts(csv_file_path)\n",
    "\n",
    "# Print the first entry to verify the format\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this modified script:\n",
    "\n",
    "1. We import cudf and cupy instead of pandas and numpy, respectively.\n",
    "2. We use cudf.read_csv to read the CSV file into a cuDF DataFrame.\n",
    "3. We perform computations on GPU where applicable, such as distance calculations, using cupy arrays.\n",
    "4. We convert cuDF Series to cupy arrays using to_array() method when necessary.\n",
    "5. We utilize GPU-accelerated operations provided by cuDF and cupy for efficient data processing.\n",
    "\n",
    "> Please make sure to review the cuDF documentation for additional details and functionalities: https://docs.rapids.ai/api/cudf/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'Anon_Pings/anon_pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'trajectories-01-31.csv'\n",
    "\n",
    "# Read CSV file into a cuDF DataFrame\n",
    "df = cudf.read_csv(input_file)\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "df['location_read_at'] = cudf.to_datetime(df['location_read_at'] / 1000, unit='s')\n",
    "\n",
    "# Function to calculate distance between two points on GPU\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1 = cp.radians(lat1)\n",
    "    lon1 = cp.radians(lon1)\n",
    "    lat2 = cp.radians(lat2)\n",
    "    lon2 = cp.radians(lon2)\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to calculate time difference in seconds\n",
    "def calculate_time_difference(time1, time2):\n",
    "    return (time2 - time1).total_seconds()\n",
    "\n",
    "# Initialize list to store trip data\n",
    "trip_data = []\n",
    "\n",
    "# Group data by booking_id to process trips separately\n",
    "grouped = df.groupby('booking_id')\n",
    "\n",
    "# Iterate over each trip\n",
    "for booking_id, group in grouped:\n",
    "    # Sort pings by timestamp\n",
    "    group = group.sort_values(by='location_read_at')\n",
    "    \n",
    "    # Extract trip information\n",
    "    driver_id = group['driver_id'].iloc[0]\n",
    "    time_id = group['location_read_at'].iloc[0]\n",
    "    lngs = group['longitude'].to_array()\n",
    "    lats = group['latitude'].to_array()\n",
    "    \n",
    "    # Initialize dist_gaps to store cumulative distances on GPU\n",
    "    dist_gaps = cp.zeros_like(lats)\n",
    "    prev_lat = lats[0]\n",
    "    prev_lng = lngs[0]\n",
    "    cum_dist = 0\n",
    "    \n",
    "    # Calculate total distance\n",
    "    for i in range(1, len(lats)):\n",
    "        lat = lats[i]\n",
    "        lng = lngs[i]\n",
    "        dist = calculate_distance(prev_lat, prev_lng, lat, lng)\n",
    "        cum_dist += dist\n",
    "        dist_gaps[i] = cum_dist\n",
    "        prev_lat = lat\n",
    "        prev_lng = lng\n",
    "    \n",
    "    total_dist = cum_dist\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = calculate_time_difference(group['location_read_at'].iloc[0], group['location_read_at'].iloc[-1])\n",
    "    \n",
    "    # Calculate time gaps\n",
    "    time_gaps = (group['location_read_at'] - time_id).dt.total_seconds().to_array()\n",
    "    \n",
    "    # Append trip data to list\n",
    "    trip_data.append([booking_id, driver_id, time_id] + [lngs, lats, total_dist, total_time, time_gaps, dist_gaps])\n",
    "\n",
    "# Create cuDF DataFrame from trip data\n",
    "output_df = cudf.DataFrame(trip_data, columns=['booking_id', 'driver_id', 'time_id', 'lngs', 'lats', 'dist', 'time', 'time_gap', 'dist_gap'])\n",
    "\n",
    "# Write output cuDF DataFrame to CSV\n",
    "output_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distance travelled from another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance travelled for booking_id 29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913: 11.79921054840088 km\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def filter_csv_by_booking_id(csv_file, booking_id):\n",
    "    with open(csv_file, 'r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Initialize distance variable\n",
    "        distance_travelled_km = None\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Check if the booking_id matches the desired booking_id\n",
    "            if row['booking_id'] == booking_id:\n",
    "                # Extract the distance_travelled_km for the matching row\n",
    "                distance_travelled_km = row['distance_travelled_km']\n",
    "                break\n",
    "        \n",
    "        # Check if distance_travelled_km was found\n",
    "        if distance_travelled_km is not None:\n",
    "            print(f\"Distance travelled for booking_id {booking_id}: {distance_travelled_km} km\")\n",
    "        else:\n",
    "            print(f\"No distance travelled found for booking_id {booking_id}\")\n",
    "\n",
    "# Example usage:\n",
    "input_csv_file = 'Pooling/anon_pooling_jan_24_amman.csv'\n",
    "desired_booking_id = '29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913'  # Replace 'ABC123' with the desired booking_id\n",
    "filter_csv_by_booking_id(input_csv_file, desired_booking_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unix to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the Unix timestamp\n",
    "unix_timestamp = 1609459200  # Replace with your actual Unix timestamp\n",
    "\n",
    "# Convert to datetime\n",
    "dt = datetime.datetime.fromtimestamp(unix_timestamp)\n",
    "\n",
    "# Print the datetime in a desired format\n",
    "print(dt.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Test CSV file with n trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "\n",
    "def filter_entries(input_file, output_file, booking_ids):\n",
    "    # Check if the output file exists, if not, create it with headers\n",
    "    file_exists = os.path.isfile(output_file)\n",
    "    with open(output_file, 'a', newline='') as csvfile:\n",
    "        fieldnames = []  # Initialize empty list for fieldnames\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            with open(input_file, 'r', newline='') as input_csv:\n",
    "                reader = csv.DictReader(input_csv)\n",
    "                fieldnames = reader.fieldnames  # Get fieldnames from input file\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "        with open(input_file, 'r', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                if row['booking_id'] in booking_ids:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'Anon_Pings/anon_pooling_pings_jan_24_amman_2024-01-31.csv'\n",
    "output_file = 'test.csv'\n",
    "booking_ids = ['88165aea83997095058b3f6676c1e3bdeedb4802c52afc9c412b1c610713a1ca',\n",
    "               '3846a90814f7e29b6b0c11717b40afd9fcd86ac7aae41fa9ffe19fbfcc4bfe26',\n",
    "               '29c5e8211f059fed952cc810e964c523e727221d0bd669001bb75c6ebd85f913']\n",
    "\n",
    "filter_entries(input_file, output_file, booking_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distance functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29400740273246023\n",
      "0.325896974688779\n",
      "0.6199043774212392\n",
      "0.47439900315363936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "lats = [30.64392,30.642129,30.64393,30.640667,30.637807,30.634062,30.630342,30.62768,30.624637,30.622056,30.620839,30.62065,30.620698,30.620622,30.620588,30.621499,30.625048,30.625105,30.625109,30.624056,30.623248,30.626844]\n",
    "lngs = [104.115353,104.113091,104.110404,104.108335,104.106304,104.104013,104.101653,104.100465,104.097907,104.095813,104.091939,104.087057,104.083797,104.080276,104.076107,104.071857,104.072423,104.072982,104.073218,104.076707,104.076795,104.076552]\n",
    "\n",
    "dist_gaps = [0] + [calculate_distance(lats[i], lngs[i], lats[i + 1], lngs[i + 1]) for i in range(len(lats)-1)]\n",
    "\n",
    "# print(dist_gaps)\n",
    "\n",
    "result1 = calculate_distance(30.64392, 104.115353, 30.642129, 104.113091)\n",
    "result2 = calculate_distance(30.642129, 104.113091, 30.64393, 104.110404)\n",
    "result3 = calculate_distance(30.64392, 104.115353, 30.64393, 104.110404)\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result1+result2)\n",
    "print(result3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
