{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main: Data Cleaner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose clean non-pooled data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching process completed. Check 'clean_trips.json' for results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "clean_file_path = \"clean_trips.json\"\n",
    "pooling_data = pd.read_csv(\"careems data/anon_pooling_jan_24_amman.csv\")\n",
    "\n",
    "filtered_pooling_data = pooling_data[pooling_data['day'] == '2024-01-31']\n",
    "\n",
    "\n",
    "with open(\"fixed_traj_new.json\", \"r\") as json_traj_file:\n",
    "    new_data = [json.loads(line) for line in json_traj_file]  #read each line as a JSON object\n",
    "\n",
    "\n",
    "\n",
    "with open(clean_file_path, 'w', encoding='utf-8') as clean_file :\n",
    "    for entry in new_data:\n",
    "        entry_time = entry[\"time\"]\n",
    "        entry_trip_id = entry[\"trip_id\"]\n",
    "        entry_driver_id = entry[\"driverID\"]\n",
    "                    \n",
    "        for _, row in filtered_pooling_data.iterrows():\n",
    "            pool_time = float(row[\"captain_engagement_time\"] * 60)\n",
    "            pool_trip_id = row[\"booking_id\"]\n",
    "            pool_driver_id = row[\"captain_id\"]\n",
    "            time_diff= pool_time - entry_time\n",
    "\n",
    "            #adding time difference to entry\n",
    "            entry_with_time_diff = entry.copy()  \n",
    "            entry_with_time_diff[\"time_diff\"] = time_diff  \n",
    "\n",
    "            #writing good trips to clean file (same trip and driver id and >5 sec time diff)\n",
    "            if entry_trip_id == pool_trip_id and entry_driver_id == pool_driver_id and abs(time_diff) <= 5:\n",
    "                json.dump(entry_with_time_diff, clean_file)\n",
    "                clean_file.write(\"\\n\")\n",
    "                break\n",
    "                       \n",
    "\n",
    "print(\"Matching process completed. Check 'clean_trips.json' for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unclean trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_unmatched_trips(new_file_path, clean_file_path, output_file_path):\n",
    "    #read data from two JSON files\n",
    "    new_trips = []\n",
    "    with open(new_file_path, 'r') as new_file:\n",
    "        for line in new_file:\n",
    "            new_trips.append(json.loads(line))\n",
    "\n",
    "    clean_trips = []\n",
    "    with open(clean_file_path, 'r') as clean_file:\n",
    "        for line in clean_file:\n",
    "            clean_trips.append(json.loads(line))\n",
    "\n",
    "    #extract trip IDs from clean_trips\n",
    "    clean_trip_ids = {trip['trip_id'] for trip in clean_trips}\n",
    "\n",
    "    #extract captain engagement times from filtered_pooling_data\n",
    "    captain_engagement_times = {row['booking_id']: float(row['captain_engagement_time'] * 60) for _, row in filtered_pooling_data.iterrows()}\n",
    "\n",
    "\n",
    "    unmatched_trips = []\n",
    "    for trip in new_trips:\n",
    "        if trip['trip_id'] not in clean_trip_ids:\n",
    "            trip_id = trip['trip_id']\n",
    "            if trip_id in captain_engagement_times:\n",
    "                \n",
    "                engagement_time = captain_engagement_times[trip_id]\n",
    "                traj_time = trip['time']\n",
    "                time_diff= engagement_time - traj_time\n",
    "\n",
    "                trip['time_diff'] = time_diff\n",
    "            \n",
    "            unmatched_trips.append(trip)\n",
    "\n",
    "\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for trip in unmatched_trips:\n",
    "            json.dump(trip, output_file)\n",
    "            output_file.write('\\n')\n",
    "\n",
    "\n",
    "traj_file_path = 'fixed_traj_new.json'\n",
    "clean_file_path = 'clean_trips.json'\n",
    "unclean_file_path = 'unclean_trips.json'\n",
    "\n",
    "\n",
    "find_unmatched_trips(traj_file_path, clean_file_path, unclean_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Pooling File by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data written to pooling_day.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the original CSV file\n",
    "pooling_data = pd.read_csv(\"careems data/anon_pooling_jan_24_amman.csv\")\n",
    "\n",
    "# Filter data for the specific day '2024-01-31'\n",
    "filtered_pooling_data = pooling_data[pooling_data['day'] == '2024-01-31']\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = \"pooling_day.csv\"\n",
    "\n",
    "# Write the filtered data to the CSV file\n",
    "filtered_pooling_data.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Filtered data written to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current workspace: Check for missing trailing pings if within wait_time_to_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "# Read the content of the JSON file\n",
    "with open(\"unclean_trips.json\", 'r', encoding='utf-8') as input_file:\n",
    "    unclean_trips = [json.loads(line) for line in input_file]  # Each line contains a JSON object\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "pooling_day = pd.read_csv(\"pooling_day.csv\")\n",
    "\n",
    "trips_not_in_pooling = 0\n",
    "no_time_diff = 0\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each entry in the JSON data\n",
    "# Iterate over each trip in unclean_trips\n",
    "with open(\"filled_end_pings2.json\", 'w', encoding='utf-8') as output_file:\n",
    "    for trip in unclean_trips:\n",
    "        trip_id = trip.get(\"trip_id\")\n",
    "\n",
    "        # Check if time_diff is valid (i.e., not None)\n",
    "        time_diff = trip.get(\"time_diff\", None)\n",
    "        if time_diff is None:\n",
    "            no_time_diff += 1\n",
    "            # print(f\"Trip {trip_id} has no valid time_diff, skipping...\")\n",
    "            continue  # Skip to the next trip if time_diff is not valid\n",
    "        \n",
    "        \n",
    "\n",
    "        time_gap = trip.get(\"time_gap\")\n",
    "        dist_gap = trip.get(\"dist_gap\")\n",
    "        lats = trip.get(\"lats\")\n",
    "        lngs = trip.get(\"lngs\")\n",
    "        time = trip.get(\"time\")\n",
    "\n",
    "        # Match trip_id from JSON with booking_id from CSV\n",
    "        matched_entry = pooling_day[pooling_day[\"booking_id\"] == trip_id]\n",
    "\n",
    "        # if matched_entry.empty:\n",
    "        #     trips_not_in_pooling += 1\n",
    "        #     # print(f\"No matching entry for Trip {trip_id} in pooling_day.csv, skipping...\")\n",
    "        #     continue  # Skip to the next trip if no match is found\n",
    "\n",
    "        # Get the wait_time_to_customer from CSV\n",
    "        wait_time_to_customer = matched_entry[\"wait_time_at_customer\"].iloc[0]\n",
    "        # print(type(matched_entry))\n",
    "        # print(matched_entry)\n",
    "        # print(type(matched_entry[\"wait_time_at_customer\"].iloc[0]))\n",
    "        # print(matched_entry[\"wait_time_at_customer\"].iloc[0])\n",
    "        # Calculate the number of additional elements to append\n",
    "        num_elements = math.floor(time_diff / 5)\n",
    "\n",
    "\n",
    "        # dump the data to a csv file as a CHECKER\n",
    "        # with open(\"checkpoint_00.csv\", \"a\") as file: \n",
    "        #     file.write(f\"{trip_id},{wait_time_to_customer},{time_diff},{num_elements}\\n\")\n",
    "\n",
    "\n",
    "        # Check the last changing coordinate in lats and lngs\n",
    "        if lats and lngs:\n",
    "            last_coord = (lats[-1], lngs[-1])\n",
    "            count = 0\n",
    "            for lat, lng in zip(reversed(lats), reversed(lngs)):\n",
    "                if (lat, lng) == last_coord:\n",
    "                    count += 1\n",
    "                    # print((lat,lng))\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "        # if(count>1):\n",
    "        #check if time of stationary coordinates + time diff from captain engagement time is within 5 seconds of wait time to customer\n",
    "            x = time-time_gap[-count]+time_diff - (wait_time_to_customer*60)\n",
    "\n",
    "            if (count>1) & (abs(x)<=5) & (time_diff>=0):\n",
    "                # write in a csv file the trip_id, count*5, and wait_time_to_customer\n",
    "                # with open(\"checkpoint_01.csv\", \"a\") as file:\n",
    "                #     file.write(f\"{trip_id},{x},{wait_time_to_customer}\\n\")\n",
    "                # continue\n",
    "\n",
    "        # Append elements based on the condition\n",
    "                for _ in range(num_elements):\n",
    "                    # Update the time_gap\n",
    "                    new_time = time_gap[-1] + 5 if time_gap else 5\n",
    "                    time_gap.append(new_time)\n",
    "\n",
    "                    # Update the dist_gap, lats, and lngs\n",
    "                    if dist_gap:\n",
    "                        dist_gap.append(dist_gap[-1])\n",
    "                        lats.append(lats[-1])\n",
    "                        lngs.append(lngs[-1])\n",
    "                    # else:\n",
    "                    #     dist_gap.append(0)\n",
    "                    #     lats.append(0)\n",
    "                    #     lngs.append(0)\n",
    "\n",
    "                # Modify the corresponding entry with new values\n",
    "                # Convert to the expected types if needed\n",
    "                trip[\"time_gap\"] = time_gap\n",
    "                trip[\"dist_gap\"] = dist_gap\n",
    "                trip[\"lats\"] = lats\n",
    "                trip[\"lngs\"] = lngs\n",
    "\n",
    "    # Write the updated JSON data to a new file\n",
    "        # for trip in unclean_trips:\n",
    "                json.dump(trip, output_file)\n",
    "                output_file.write(\"\\n\")  # Write each trip on a new line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load data from unclean_trips.json\n",
    "with open('unclean_trips.json', 'r') as f:\n",
    "    unclean_trips = json.load(f)\n",
    "\n",
    "# Load data from pooling.csv\n",
    "pooling_data = pd.read_csv('pooling_day.csv')\n",
    "\n",
    "# Assuming the pooling.csv has a column named 'wait_time_to_customer'\n",
    "wait_time_to_customer = pooling_data['wait_time_to_customer'][0]  # Change index as appropriate\n",
    "\n",
    "# Extract time_diff from unclean_trips\n",
    "time_diff = unclean_trips.get('time_diff', 0)\n",
    "\n",
    "# Calculate the number of extra elements to be added\n",
    "extra_elements_count = math.floor(time_diff / 5)\n",
    "\n",
    "# Get existing lists from unclean_trips\n",
    "time_gap = unclean_trips.get('time_gap', [])\n",
    "dist_gap = unclean_trips.get('dist_gap', [])\n",
    "lats = unclean_trips.get('lats', [])\n",
    "lngs = unclean_trips.get('lngs', [])\n",
    "\n",
    "# Find the last changing coordinate in lats and lngs\n",
    "last_unique_lat, last_unique_lng = None, None\n",
    "\n",
    "# Iterate from the end to find the last unique coordinate\n",
    "for i in range(len(lats) - 1, -1, -1):\n",
    "    if lats[i] != last_unique_lat or lngs[i] != last_unique_lng:\n",
    "        last_unique_lat, last_unique_lng = lats[i], lngs[i]\n",
    "        break\n",
    "\n",
    "# Count the number of elements from this last unique coordinate to the end\n",
    "last_change_index = lats.index(last_unique_lat)\n",
    "elements_since_last_change = len(lats) - last_change_index\n",
    "\n",
    "# Condition check: if this count multiplied by 5 is less than wait_time_to_customer\n",
    "if (elements_since_last_change * 5) < wait_time_to_customer:\n",
    "    # Update the time_gap\n",
    "    last_time = time_gap[-1] if time_gap else 0\n",
    "    for i in range(extra_elements_count):\n",
    "        new_time = last_time + (5 * (i + 1))\n",
    "        time_gap.append(new_time)\n",
    "        dist_gap.append(dist_gap[-1] if dist_gap else 0)  # Append the last element value\n",
    "        lats.append(lats[-1] if lats else last_unique_lat)  # Append the last lat value\n",
    "        lngs.append(lngs[-1] if lngs else last_unique_lng)  # Append the last lng value\n",
    "\n",
    "    # Set the time attribute\n",
    "    unclean_trips['time'] = 5 * extra_elements_count\n",
    "\n",
    "    # Save the updated JSON back to file\n",
    "    with open('updated_unclean_trips.json', 'w') as f:\n",
    "        json.dump(unclean_trips, f, indent=4)\n",
    "\n",
    "    print(\"Updated unclean_trips.json based on the specified condition.\")\n",
    "\n",
    "else:\n",
    "    print(\"Condition not met, no updates made to unclean_trips.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3,4,5,6,7,8,9,10]\n",
    "print(test[-4])\n",
    "\n",
    "entry[30] == entry[-1]\n",
    "entry[30 - c +1] == entry[-c]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
