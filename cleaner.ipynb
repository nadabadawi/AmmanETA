{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN: Data Cleaner\n",
    "#### Choose clean non-pooled data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching process completed. Check 'clean_trips.json' for results.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert time in seconds to floating-point seconds\n",
    "def convert_to_seconds(time, unit):\n",
    "    if unit == \"seconds\":\n",
    "        return float(time)\n",
    "    elif unit == \"minutes\":\n",
    "        return float(time) * 60  # Convert minutes to seconds\n",
    "\n",
    "# Step 1: Load the data from \"new.json\" with multiple JSON objects separated by new lines\n",
    "with open(\"new.json\", \"r\") as json_file:\n",
    "    new_data = [json.loads(line) for line in json_file]  # Read each line as a JSON object\n",
    "\n",
    "# Step 2: Load the data from \"pooling.csv\"\n",
    "pooling_data = pd.read_csv(\"anon_pooling_jan_24_amman.csv\")\n",
    "\n",
    "# Step 3: Filter pooling_data to only include records with the 'day' attribute set to '2024-01-31'\n",
    "filtered_pooling_data = pooling_data[pooling_data['day'] == '2024-01-31']\n",
    "\n",
    "output_file = \"pooling_by_day.csv\"\n",
    "filtered_pooling_data.to_csv(output_file, index=False)\n",
    "# with open(\"pooling_by_day.csv\", \"w\") as output_file:\n",
    "    # json.dump(filtered_pooling_data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching process completed. Check 'clean_trips.json' for results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"pooling_by_day.csv\"\n",
    "filtered_pooling_data = pd.read_csv(input_file)\n",
    "\n",
    "# Step 1: Load the data from \"new.json\" with multiple JSON objects separated by new lines\n",
    "with open(\"new.json\", \"r\") as json_file:\n",
    "    new_data = [json.loads(line) for line in json_file]  # Read each line as a JSON object\n",
    "\n",
    "output_file = \"clean_trips.json\"\n",
    "\n",
    "# Step 3: Initialize an empty list to store matched records\n",
    "# matched_records = []\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "# Step 4: Iterate over the data from \"new.json\"\n",
    "    for entry in new_data:\n",
    "        entry_time = entry[\"time\"]\n",
    "        entry_trip_id = entry[\"trip_id\"]\n",
    "        entry_driver_id = entry[\"driverID\"]\n",
    "\n",
    "        # Step 5: Search for a matching entry in \"pooling.csv\"\n",
    "        for _, row in filtered_pooling_data.iterrows():\n",
    "            pool_time = float(row[\"captain_engagement_time\"] * 60)\n",
    "            pool_trip_id = row[\"booking_id\"]\n",
    "            pool_driver_id = row[\"captain_id\"]\n",
    "\n",
    "            # Step 6: Check for trip_id, driver_id, and time margin of 5 seconds\n",
    "            if (entry_trip_id == pool_trip_id and\n",
    "                entry_driver_id == pool_driver_id and\n",
    "                abs(pool_time - entry_time) <= 5):\n",
    "                # If match found, add to matched_records\n",
    "                # matched_records.append(entry)\n",
    "                # with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                #     output_file.write(entry)\n",
    "                json.dump(entry, output_file)\n",
    "                output_file.write(\"\\n\")\n",
    "                break\n",
    "\n",
    "# Step 7: Write the matched records to \"clean_trips.json\"\n",
    "# with open(\"clean_trips.json\", \"w\") as output_file:\n",
    "#     json.dump(matched_records, output_file)\n",
    "\n",
    "print(\"Matching process completed. Check 'clean_trips.json' for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unclean trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not this version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched trips found and saved to 'unmatched_trips.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file and return its content\n",
    "def read_json(filename):\n",
    "   data=[]\n",
    "   with open(filename, 'r') as file:\n",
    "        # data = json.load(file)\n",
    "        for i in file:\n",
    "         data.append(json.loads(i))   \n",
    "   return data\n",
    "\n",
    "# Function to write a JSON file\n",
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Read data from the two JSON files\n",
    "new_trips = read_json('new_uncleaned1.json')  # Reading new data\n",
    "clean_trips = read_json('clean_trips.json')  # Reading existing clean trips\n",
    "\n",
    "\n",
    "# Set of booking IDs in clean_trips.json for faster lookup\n",
    "clean_booking_ids = {trip['trip_id'] for trip in clean_trips}\n",
    "\n",
    "# List to store unmatched trips\n",
    "unmatched_trips = []\n",
    "\n",
    "# Check each entry in new_trips to see if its booking_id is in clean_booking_ids\n",
    "for trip in new_trips:\n",
    "    booking_id = trip.get('trip_id')\n",
    "    if booking_id not in clean_booking_ids:\n",
    "        # If the booking ID is not in clean trips, add it to unmatched_trips\n",
    "        unmatched_trips.append(trip)\n",
    "\n",
    "# If there are unmatched trips, write them to a new JSON file\n",
    "if unmatched_trips:\n",
    "    write_json(unmatched_trips, 'unmatched_trips.json')  # Write to a new file\n",
    "    print(\"Unmatched trips found and saved to 'unmatched_trips.json'.\")\n",
    "else:\n",
    "    print(\"No unmatched trips found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_unmatched_trips(new_file_path, clean_file_path, output_file_path):\n",
    "    # Read data from the two JSON files\n",
    "    new_trips = []\n",
    "    with open(new_file_path, 'r') as new_file:\n",
    "        for line in new_file:\n",
    "            new_trips.append(json.loads(line))\n",
    "\n",
    "    clean_trips = []\n",
    "    with open(clean_file_path, 'r') as clean_file:\n",
    "        for line in clean_file:\n",
    "            clean_trips.append(json.loads(line))\n",
    "\n",
    "    # Extract trip IDs from clean_trips\n",
    "    clean_trip_ids = {trip['trip_id'] for trip in clean_trips}\n",
    "\n",
    "    # Find unmatched trips\n",
    "    unmatched_trips = [trip for trip in new_trips if trip['trip_id'] not in clean_trip_ids]\n",
    "\n",
    "    # Write unmatched trips to a new JSON file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for trip in unmatched_trips:\n",
    "            json.dump(trip, output_file)\n",
    "            output_file.write('\\n')\n",
    "\n",
    "# Example usage:\n",
    "new_file_path = 'new_uncleaned1.json'\n",
    "clean_file_path = 'clean_trips.json'\n",
    "output_file_path = 'unmatched_trips2.json'\n",
    "\n",
    "find_unmatched_trips(new_file_path, clean_file_path, output_file_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
